{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65147ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eco_health_analysis.py\n",
    "# © 2025. Можно свободно модифицировать и использовать.\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import warnings\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lightgbm import LGBMRegressor\n",
    "import shap\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")      # приглушаем «лишние» ворнинги\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 1. ПАРАМЕТРЫ ПОЛЬЗОВАТЕЛЯ\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "DATA_PATH   = \"тест.xlsx\"              # исходная таблица (можно .csv)\n",
    "TARGET_COL  = \"Всего заболеваний\"      # целевая переменная (заболеваемость на 100 тыс.)\n",
    "YEAR_COL    = \"Год\"\n",
    "REGION_COL  = \"Район\"\n",
    "# целевые нозологии: задавайте список колонок с интересующими болезнями,\n",
    "# либо оставьте одну общую («Всего заболеваний»)\n",
    "# Например: TARGET_GROUP = [\"Болезни органов дыхания\", \"Злокачественные новообразования\"]\n",
    "TARGET_GROUP: List[str] = [TARGET_COL]\n",
    "\n",
    "# сколько топ‑факторов рисовать на dependence‑plots\n",
    "N_TOP_DEP   = 3\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 2. ЧТЕНИЕ И ПРЕДОБРАБОТКА\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "out_dir = pathlib.Path(\"outputs\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"► читаем данные…\")\n",
    "if DATA_PATH.endswith(\".csv\"):\n",
    "    df = pd.read_csv(DATA_PATH, encoding=\"utf-8-sig\")\n",
    "else:\n",
    "    df = pd.read_excel(DATA_PATH)\n",
    "\n",
    "# убираем возможные пробелы вокруг имён колонок\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# > превращаем запятые в числа, если вдруг остались строки\n",
    "numeric_cols = df.columns.difference([YEAR_COL, REGION_COL])\n",
    "df[numeric_cols] = df[numeric_cols].replace(\",\", \".\", regex=True).apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# ── лаговые признаки (экология за прошлый год) ────────────────────────────────\n",
    "eco_cols = [c for c in df.columns if c.startswith((\"Air_\", \"Water_\", \"Soil_\"))]\n",
    "df = df.sort_values([REGION_COL, YEAR_COL])\n",
    "df_lag = df[[REGION_COL, YEAR_COL] + eco_cols].copy()\n",
    "df_lag[eco_cols] = df_lag.groupby(REGION_COL)[eco_cols].shift(1)\n",
    "df_lag.columns = [c + \"_lag1\" if c in eco_cols else c for c in df_lag.columns]\n",
    "\n",
    "df = df.merge(df_lag, on=[REGION_COL, YEAR_COL], how=\"left\")\n",
    "\n",
    "# ── трендовые графики (по желанию) ────────────────────────────────────────────\n",
    "def plot_trends():\n",
    "    # усредняем по всем регионам: один график «экология» и один «заболеваемость»\n",
    "    mean_env = df.groupby(YEAR_COL)[eco_cols].mean()\n",
    "    target   = df.groupby(YEAR_COL)[TARGET_COL].mean()\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(target.index, target.values, label=\"Заболеваемость (средняя)\", lw=2)\n",
    "    ax2.plot(mean_env.index, mean_env[\"Air_Аммиак\"].values, color=\"tab:red\", label=\"Аммиак (сред.)\")\n",
    "    ax1.set_xlabel(\"Год\")\n",
    "    ax1.set_ylabel(\"Заболеваемость на 100 тыс.\")\n",
    "    ax2.set_ylabel(\"Аммиак, мг/м³\")\n",
    "    ax1.legend(loc=\"upper left\"); ax2.legend(loc=\"upper right\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_dir / \"trend_example.png\")\n",
    "    plt.close()\n",
    "\n",
    "plot_trends()\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 3. ЛИНЕЙНАЯ МОДЕЛЬ (OLS)\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "def build_linear_model(df_in: pd.DataFrame, target: str):\n",
    "    predictors = eco_cols + [c + \"_lag1\" for c in eco_cols]\n",
    "    X = df_in[predictors]\n",
    "    y = df_in[target]\n",
    "    X = sm.add_constant(X)                         # добавляем константу\n",
    "    # простейшая median‑импутация (statsmodels не любит NaN)\n",
    "    X = X.fillna(X.median(numeric_only=True))\n",
    "    y = y.fillna(y.median())\n",
    "\n",
    "    model = sm.OLS(y, X).fit(cov_type=\"HC3\")       # робастные ошибки\n",
    "    model_summary_path = out_dir / f\"ols_summary_{target}.txt\"\n",
    "    with open(model_summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(model.summary().as_text())\n",
    "    print(f\"► OLS готов — сохранён {model_summary_path}\")\n",
    "\n",
    "    # рисуем столбики коэффициентов ±95 % ДИ\n",
    "    coefs = model.params.drop(\"const\")\n",
    "    errs  = model.bse.drop(\"const\") * 1.96\n",
    "    plt.figure(figsize=(6, 10))\n",
    "    coefs.sort_values().plot(kind=\"barh\", xerr=errs.loc[coefs.index])\n",
    "    plt.title(f\"Коэффициенты OLS для «{target}»\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_dir / f\"ols_coefs_{target}.png\")\n",
    "    plt.close()\n",
    "\n",
    "for tgt in TARGET_GROUP:\n",
    "    build_linear_model(df, tgt)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 4. ML‑МОДЕЛЬ + SHAP\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "def build_ml_model(df_in: pd.DataFrame, target: str):\n",
    "    # признаки — все экологии + лаги; можно добавить dummy‑код «Год» / «Район» при желании\n",
    "    X = df_in[eco_cols + [c + \"_lag1\" for c in eco_cols]]\n",
    "    y = df_in[target]\n",
    "\n",
    "    # train/test: последние 2 года — test\n",
    "    train_mask = df_in[YEAR_COL] < df_in[YEAR_COL].max() - 1\n",
    "    X_train, X_test = X[train_mask], X[~train_mask]\n",
    "    y_train, y_test = y[train_mask], y[~train_mask]\n",
    "\n",
    "    # Импутация пропусков + модель\n",
    "    imp = SimpleImputer(strategy=\"median\")\n",
    "    X_train_imp = imp.fit_transform(X_train)\n",
    "    X_test_imp  = imp.transform(X_test)\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        n_estimators=600,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "    )\n",
    "    model.fit(X_train_imp, y_train)\n",
    "\n",
    "    # оценка\n",
    "    y_pred = model.predict(X_test_imp)\n",
    "    r2  = r2_score(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    print(f\"► ML‑модель «{target}»:  R²={r2:.3f},  RMSE={rmse:.1f}\")\n",
    "\n",
    "    # SHAP\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train_imp)\n",
    "\n",
    "    # bar\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values, X_train, plot_type=\"bar\", show=False)\n",
    "    plt.title(f\"SHAP важность факторов – {target}\")\n",
    "    plt.tight_layout(); plt.savefig(out_dir / f\"shap_bar_{target}.png\"); plt.close()\n",
    "\n",
    "    # beeswarm\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values, X_train, show=False)\n",
    "    plt.tight_layout(); plt.savefig(out_dir / f\"shap_beeswarm_{target}.png\"); plt.close()\n",
    "\n",
    "    # dependence plots для топ‑N\n",
    "    importance = np.abs(shap_values).mean(axis=0)\n",
    "    top_idx = np.argsort(importance)[-N_TOP_DEP:][::-1]\n",
    "    for i in top_idx:\n",
    "        feature = X_train.columns[i]\n",
    "        shap.dependence_plot(i, shap_values, X_train, show=False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_dir / f\"shap_dep_{target}_{feature}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    # один waterfall для первого тест‑наблюдения\n",
    "    shap.plots.waterfall(explainer(X_test_imp[0]), show=False, max_display=10)\n",
    "    plt.tight_layout(); plt.savefig(out_dir / f\"shap_waterfall_{target}.png\"); plt.close()\n",
    "\n",
    "for tgt in TARGET_GROUP:\n",
    "    build_ml_model(df, tgt)\n",
    "\n",
    "print(f\"► Все результаты и графики лежат в папке: {out_dir.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
