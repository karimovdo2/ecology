# app.py
# Streamlitâ€‘Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ: XGBoost + SHAP, Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ²Ñ‹Ğ²Ğ¾Ğ´
# ------------------------------------------------------
import streamlit as st, warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.inspection import PartialDependenceDisplay
from sklearn.pipeline import Pipeline
from xgboost import XGBRegressor
import shap, os

warnings.filterwarnings("ignore")
sns.set_style("whitegrid")
plt.rcParams["figure.dpi"] = 110
st.set_page_config(page_title="Ecoâ€‘HealthÂ XGB", layout="wide")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("Ğ­ĞºĞ¾Ğ»Ğ¾Ğ³Ğ¸Ñ â†’ Ğ·Ğ°Ğ±Ğ¾Ğ»ĞµĞ²Ğ°ĞµĞ¼Ğ¾ÑÑ‚ÑŒÂ :  XGBoostÂ +Â SHAP")

upl = st.file_uploader("Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ .xlsx Ğ¸Ğ»Ğ¸ .csv", type=("xlsx", "csv"))
if not upl:
    st.stop()

df = pd.read_csv(upl) if upl.name.lower().endswith(".csv") else pd.read_excel(upl, engine="openpyxl")

year_col   = st.selectbox("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ğ³Ğ¾Ğ´Ğ°", sorted([c for c in df.columns if df[c].dtype != "object"]))
region_col = st.selectbox("ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ñ€Ğ°Ğ¹Ğ¾Ğ½Ğ°", sorted(df.select_dtypes("object").columns))
target_col = st.selectbox("Ğ¦ĞµĞ»ĞµĞ²Ğ°Ñ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ", sorted([c for c in df.columns if c not in [year_col, region_col]]))

min_nonmiss = st.slider("ĞœĞ¸Ğ½. Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ°", 0.1, 0.9, 0.3, 0.05)
test_years  = st.slider("Ğ›ĞµÑ‚ Ğ² Ñ‚ĞµÑÑ‚Ğµ", 1, 3, 1)
max_depth   = st.slider("max_depth", 2, 10, 6)
n_estim     = st.slider("n_estimators", 100, 2000, 1000, 100)

if not st.button("ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·"):
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ¸ ĞºÑÑˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner=False)
def train_cache(df, year_col, region_col, target_col,
                min_nonmiss, test_years, max_depth, n_estim):
    eco_cols = [c for c in df.columns if c.startswith(("Air_", "Water_", "Soil_"))]
    for c in eco_cols:
        lag = f"{c}_lag1"
        if lag not in df.columns:
            df[lag] = df.groupby(region_col)[c].shift(1)

    num_cols  = eco_cols + [f"{c}_lag1" for c in eco_cols]
    good_cols = [c for c in num_cols if df[c].notna().mean() >= min_nonmiss]

    train_mask = df[year_col] < df[year_col].max() - test_years
    X_train = df.loc[train_mask, good_cols + [region_col]]
    y_train = df.loc[train_mask, target_col]
    X_test  = df.loc[~train_mask, good_cols + [region_col]]
    y_test  = df.loc[~train_mask, target_col]

    pipe = Pipeline([
        ("prep", ColumnTransformer(
            [("cat", OneHotEncoder(handle_unknown="ignore"),
              [X_train.columns.get_loc(region_col)])],
            remainder="passthrough", sparse_threshold=0.3)),
        ("xgb", XGBRegressor(
            n_estimators=n_estim, max_depth=max_depth,
            learning_rate=0.045, subsample=0.8,
            colsample_bytree=0.8, reg_lambda=1.0,
            random_state=42, n_jobs=-1, missing=np.nan))





    ]).fit(X_train, y_train)

    return df, good_cols, pipe, X_train, y_train, X_test, y_test

with st.spinner("â³ ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ XGBoostâ€¦"):
    df, good_cols, pipe, X_tr, y_tr, X_te, y_te = train_cache(
        df.copy(), year_col, region_col, target_col,
        min_nonmiss, test_years, max_depth, n_estim)
st.success("âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ°")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
y_pred = pipe.predict(X_te)
R2  = r2_score(y_te, y_pred)
RMSE = mean_squared_error(y_te, y_pred, squared=False)
MAE  = mean_absolute_error(y_te, y_pred)
cv_r2 = cross_val_score(pipe, X_tr, y_tr,
                        cv=TimeSeriesSplit(n_splits=5), scoring="r2")

st.markdown(f"### ğŸ¯ Holdâ€‘outÂ RÂ² **{R2:.3f}**Â Â Â |Â Â Â CVÂ RÂ² **{cv_r2.mean():.3f}Â Â±Â {cv_r2.std():.3f}**")
st.caption(f"RMSEÂ {RMSE:,.0f} Â Â |Â Â  MAEÂ {MAE:,.0f}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Gainâ€‘Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
feat_names = pipe.named_steps["prep"].get_feature_names_out()
gain = pipe.named_steps["xgb"].get_booster().get_score(importance_type="gain")
gain_s = pd.Series(gain).reindex(feat_names, fill_value=0).sort_values(ascending=False)

fig, ax = plt.subplots(figsize=(6,8))
sns.barplot(y=gain_s.head(20).index, x=gain_s.head(20).values, palette="viridis", ax=ax)
ax.set_title("XGB gain importance"); ax.set_xlabel("gain"); ax.set_ylabel("")
st.pyplot(fig)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SHAP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.spinner("SHAP (Ğ¿Ğ¾Ğ´Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ° 400 ÑÑ‚Ñ€Ğ¾Ğº)â€¦"):
    X_tr_enc = pipe.named_steps["prep"].transform(X_tr)
    sub = np.random.choice(X_tr_enc.shape[0], size=min(400, X_tr_enc.shape[0]), replace=False)
    explainer   = shap.TreeExplainer(pipe.named_steps["xgb"])
    shap_values = explainer.shap_values(X_tr_enc[sub])

shap_abs = np.abs(shap_values).mean(axis=0)
shap_df  = pd.DataFrame({"feature": feat_names, "shap": shap_abs}).sort_values("shap", ascending=False)

# bar
fig, ax = plt.subplots(figsize=(6,8))
sns.barplot(y=shap_df.head(20)["feature"], x=shap_df.head(20)["shap"], palette="magma", ax=ax)
ax.set_title("Global SHAP importance"); ax.set_xlabel("|SHAP|"); ax.set_ylabel("")
st.pyplot(fig)

# beeswarm
st.subheader("SHAP beeswarm")
shap.summary_plot(shap_values, pd.DataFrame(X_tr_enc[sub], columns=feat_names),
                  show=False, max_display=25, plot_size=(8,6))
st.pyplot(plt.gcf())   # Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ñ„Ğ¸Ğ³.
plt.clf()

# dependence
st.subheader("SHAP dependence (Ñ‚Ğ¾Ğ¿â€‘3)")
for feat in shap_df.head(3)["feature"]:
    shap.dependence_plot(feat, shap_values,
                         pd.DataFrame(X_tr_enc[sub], columns=feat_names),
                         show=False, interaction_index=None, alpha=0.4)
    st.pyplot(plt.gcf()); plt.clf()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Partial dependence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
num_feats = [f for f in shap_df["feature"] if f.startswith("remainder__")]
top_raw   = [f.replace("remainder__", "") for f in num_feats[:3]]
if top_raw:
    st.subheader("Partial dependence (Ñ‚Ğ¾Ğ¿â€‘Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ñ…)")
    for raw in top_raw:
        fig, ax = plt.subplots(figsize=(5,3))
        PartialDependenceDisplay.from_estimator(pipe, X_tr, [raw], ax=ax, grid_resolution=50)
        st.pyplot(fig)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Scatter & residuals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
c1, c2 = st.columns(2)
with c1:
    fig, ax = plt.subplots(figsize=(4,4))
    sns.scatterplot(x=y_te, y=y_pred, ax=ax)
    ax.plot([y_te.min(), y_te.max()], [y_te.min(), y_te.max()], "--k")
    ax.set_xlabel("Ğ¤Ğ°ĞºÑ‚"); ax.set_ylabel("ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ·"); ax.set_title("Test: Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ· vs Ñ„Ğ°ĞºÑ‚")
    st.pyplot(fig)
with c2:
    fig, ax = plt.subplots(figsize=(4,3))
    sns.histplot(y_te - y_pred, bins=30, kde=True, ax=ax)
    ax.set_title("Ğ“Ğ¸ÑÑ‚Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° Ğ¾ÑÑ‚Ğ°Ñ‚ĞºĞ¾Ğ²"); ax.set_xlabel("Residual")
    st.pyplot(fig)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ğ¢Ñ€ĞµĞ½Ğ´Ñ‹ Ğ¿Ğ¾ Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½Ğ°Ğ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("Ğ“Ğ¾Ğ´Ğ¾Ğ²Ñ‹Ğµ Ñ‚Ñ€ĞµĞ½Ğ´Ñ‹ (Ñ‚Ğ¾Ğ¿â€‘6 Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½Ğ¾Ğ²)")
top_regions = df.groupby(region_col)[target_col].mean().sort_values(ascending=False).head(6).index
for reg in top_regions:
    sub = df[df[region_col]==reg].sort_values(year_col)
    sub_enc = pipe.named_steps["prep"].transform(sub[good_cols + [region_col]])
    sub["pred"] = pipe.named_steps["xgb"].predict(sub_enc)
    fig, ax = plt.subplots(figsize=(5,2.5))
    ax.plot(sub[year_col], sub[target_col], "-o", label="Ğ¤Ğ°ĞºÑ‚")
    ax.plot(sub[year_col], sub["pred"], "-s", label="ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ·")
    ax.set_title(reg); ax.set_xlabel("Ğ“Ğ¾Ğ´"); ax.set_ylabel("")
    ax.legend(); st.pyplot(fig)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¾Ğ² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
stats_rows = []
for feat in shap_df.head(25)["feature"]:
    raw = feat.replace("remainder__", "").replace("cat__", "")
    pearson = df[[raw, target_col]].corr().iloc[0,1] if raw in df else np.nan
    idx = list(feat_names).index(feat)
    stats_rows.append(dict(
        feature=feat,
        pearson_corr=pearson,
        shap_mean=float(shap_values[:, idx].mean()),
        shap_sd=float(shap_values[:, idx].std()),
        nonmiss_ratio=float(df[raw].notna().mean()) if raw in df else np.nan
    ))
stats_df = pd.DataFrame(stats_rows)
st.dataframe(stats_df)

csv = stats_df.to_csv(index=False).encode()
st.download_button("â¬‡ï¸ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ CSV", csv, "predictor_stats.csv", "text/csv")
